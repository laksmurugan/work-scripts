{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, parse_qs, parse_qsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_mmc_list = []\n",
    "with open('Bad_Marketing_Requests.csv') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    for row in readCSV:\n",
    "        try:\n",
    "            if 'cm_mmc' in row[0]:\n",
    "                a = parse_qs(row[0])['cm_mmc']\n",
    "                if a not in cm_mmc_list:\n",
    "                    cm_mmc_list.append(a)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"parsed_cm_mmc_2.csv\", \"w\") as output_file:\n",
    "    for value in cm_mmc_list:\n",
    "        output_file.write(value[0])\n",
    "        output_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load partner ID mapping to Partner name\n",
    "affiliate_mapping = {}\n",
    "with open('affiliate_mapping.csv', encoding='utf-8') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    for row in readCSV:\n",
    "        affiliate_mapping[row[2]]=row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'LinkshareID'\n",
      "'LinkshareID'\n"
     ]
    }
   ],
   "source": [
    "# Special File for Affiliate\n",
    "saffiliateurls = []\n",
    "pidnotfound=[]\n",
    "with open('Bad_Marketing_Requests.csv') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    for row in readCSV:\n",
    "        a=[]\n",
    "        try:\n",
    "            if 'LinkshareID' in row[0]:\n",
    "                pid = parse_qs(row[0])['LinkshareID']\n",
    "                pid = pid[0][0:11]\n",
    "                url = row[0][51:]\n",
    "                try:\n",
    "                    a.append(affiliate_mapping[pid])\n",
    "                except:\n",
    "                    a.append(\"\")     \n",
    "                a.append(pid)\n",
    "                a.append(url)\n",
    "                affiliateurls.append(a)\n",
    "        except Exception as e:\n",
    "            if pid not in pidnotfound:\n",
    "                pidnotfound.append(pid)\n",
    "            print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "789\n"
     ]
    }
   ],
   "source": [
    "#number of urls extracted\n",
    "print(len(affiliateurls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the parsed affiliate partner and url to file\n",
    "with open(\"affiliate_urls_parsed.csv\", \"w\") as output_file:\n",
    "    writer = csv.writer(output_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL, lineterminator='\\n')\n",
    "    writer.writerow(['Partner Name', 'Partner ID', 'URL'])\n",
    "    for item in affiliateurls:\n",
    "        writer.writerow([item[0], item[1], item[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleo's DSA spreadshee\n",
    "dsa_urls_review=[]\n",
    "with open('DSA_landing_page.csv') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    for row in readCSV:\n",
    "        url = row[2]\n",
    "        if \"/shop/product\" not in url and \"/shop/featured\" not in url and \"id=\" not in url.lower() and \"l.macys.com\" not in url:\n",
    "            dsa_urls_review.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Google_Beauty_Brand', '885-048-7688', 'https://www.macys.com/shop/makeup-and-perfume/clinique-fragrance/Fragrance,Fragrance_size/Happy,Travel%20Size', 'Beauty - DSA', 'Beauty', 'USD', '0', '4', '0.00%', '0', '0', '0'], ['Google_Beauty_Brand', '885-048-7688', 'https://www.macys.com/shop/makeup-and-perfume/hair-care-products/Hair_care_type/Hair%20Dryers', 'Beauty - DSA - RLSA', 'Beauty', 'USD', '1', '12', '8.33%', '0.35', '0.35', '0'], ['Google_Beauty_Brand', '885-048-7688', 'https://www.macys.com/shop/makeup-and-perfume/mens-hair-care', 'DSA - Page Feeds - RLSA', 'Beauty', 'USD', '0', '0', '0.00%', '0', '0', '0'], ['Google_Beauty_Brand', '885-048-7688', 'https://www.macys.com/shop/makeup-and-perfume/cologne-for-men', 'DSA - Page Feeds - RLSA', 'Beauty', 'USD', '0', '0', '0.00%', '0', '0', '0']]\n"
     ]
    }
   ],
   "source": [
    "print(dsa_urls_review[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write potential bad DSA urls to a file\n",
    "with open(\"DSA_broken_urls.csv\", \"w\") as output_file:\n",
    "    writer = csv.writer(output_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL, lineterminator='\\n')\n",
    "    for item in dsa_urls_review:\n",
    "        writer.writerow(item)\n",
    "\n",
    "# write only /shop urls to a file\n",
    "with open(\"DSA_broken_urls_2.csv\", \"w\") as output_file:\n",
    "    writer = csv.writer(output_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL, lineterminator='\\n')\n",
    "    for item in dsa_urls_review:\n",
    "        if \"/shop\" in item[2]:\n",
    "            writer.writerow(item)\n",
    "            \n",
    "# write the urls NOT LIKE /shop to a file\n",
    "with open(\"DSA_broken_urls_3.csv\", \"w\") as output_file:\n",
    "    writer = csv.writer(output_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL, lineterminator='\\n')\n",
    "    for item in dsa_urls_review:\n",
    "        if \"/shop\" not in item[2]:\n",
    "            writer.writerow(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.error import HTTPError\n",
    "import urllib.request\n",
    "\n",
    "def getResponseCode(url):\n",
    "    try:\n",
    "        conn = urllib.request.urlopen(url)\n",
    "        return conn.getcode()\n",
    "    except HTTPError as e:\n",
    "        return e.code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302\n"
     ]
    }
   ],
   "source": [
    "print(getResponseCode('https://www.macys.com/'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
